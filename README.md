# ğŸš€ Tasks Generator â€“ Backend

## ğŸ“Œ Required Project Files

This repository includes:

- `README.md` â€” Setup instructions and project overview
- `AI_NOTES.md` â€” Explanation of AI usage in development
- `ABOUTME.md` â€” Author information and resume
- `PROMPTS_USED.md` â€” Prompts used during development (without responses or API keys)

---

## âš™ï¸ How to Run Locally

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the root directory:

```env
DATABASE_URL=your_database_url
OPENAI_API_KEY=your_openai_key
```

---

### 3ï¸âƒ£ Run the Server

```bash
uvicorn app.main:app --reload
```

Backend runs at:

```
http://localhost:8000
```

---

## ğŸ“¦ API Endpoints

### `POST /generate/`

Generate structured user stories and engineering tasks.

---

### `GET /specs/`

Retrieve the last 5 generated specifications.

---

### `GET /health/`

Check backend and LLM configuration status.

---

## âœ… Features Implemented

- LLM-powered task generation
- Structured prompt design
- Database persistence
- History retrieval (last 5 specs)
- Health check endpoint
- Environment-based configuration
- CORS middleware support
- Deployed on Render

---

## âš ï¸ Not Implemented / Known Limitations

- No authentication
- No user-specific specification storage
- No pagination
- No rate limiting
- No advanced request validation schema
- No automated tests
- No structured JSON output from LLM (currently Markdown output)
- No background job queue

---

## ğŸŒ Deployment

Backend is deployed on:

- **Render** (Web Service)
- **Supabase** (PostgreSQL Database)

---

### âš ï¸ Note

Render free tier may experience cold start delays.